{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "573cd322",
   "metadata": {},
   "source": [
    "## TOOL UPDATED: December 12 2023, Henrik Loecke\n",
    "\n",
    "##Double click this cell to see full description.\n",
    "\n",
    "##You must restart the kernel after updating System_Assessment_Variables!\n",
    "\n",
    "<!-- \n",
    "\n",
    "To run this notebook, click menu Cell -> Run All\n",
    "\n",
    "User input has been moved away from this notebook so it can easily be replaced by new versions.\n",
    " \n",
    "Please open System_Assessment_Generate_Models_Variables, in the same folder as this notebook, to edit user input there.\n",
    "\n",
    "All variables with path must start with 'r', e.g. r'C:\\Projects'\n",
    "\n",
    "It must contain the following variables:\n",
    "\n",
    "model_area:                          Short area name like 'VSA' or LISA'  \n",
    "generate_future:                     Generate future population models (True/False)\n",
    "                                     If True, the same models will be used for the other models (BSF etc.)\n",
    "                                     If False, the other models will instead be made from all models in the folder.\n",
    "generate_bsf:                        Generate BSF models (True/False)\n",
    "generate_xadwf:                      Generate X times ADWF models (True/False)\n",
    "generate_sealed_vfd                  Generate sealed and/or VFD models (True/False)\n",
    "generate_AD                          Generate AD models (True/False)\n",
    "\n",
    "output_folder:                       Where the new models are created. It is recommended to use an empty folder.\n",
    "script_path:                         Path to a template of the WaterspillDischarge.cs script.\n",
    "\n",
    "#For all models:\n",
    "version:                             Model version from the backup log.\n",
    "\n",
    "#For future models\n",
    "model_original:                      The model copied for future population models. It is usually the master model.\n",
    "year_original:                       The original population year. It is used for search/replace to the new year.\n",
    "year_scenario_list:                  List of lists of years to create, which scenario to use and which to include to batch.\n",
    "population_sheet:                    The source population workbook.\n",
    "population_tab:                      The sheet name within the source population sheet.\n",
    "\n",
    "#For sealed VFD\n",
    "vfd_all:                             Create VFD for all pump stations (except the exclusions below)\n",
    "seal_all:                            Seal all nodes and deactivate weirs listed below.\n",
    "excluded_asset_names:                List of PS asset name\n",
    "weir_turn_offs:                      Weirs to deactivate if VFD model is made.\n",
    "\n",
    "#For BSF\n",
    "inis                                 List of inis in m3/ha,d. Example for 1 and 2 I/I: [11.2,22.4]\n",
    "\n",
    "#For X ADWF\n",
    "times_adwf_list                      List of X ADWF. Example for 3 and 4 ADWF: [3,4]\n",
    "\n",
    "#For AD\n",
    "dfs0_file:                           Dfs0 file with runoff result (used if runoff is traced).\n",
    "model_suffix:                        Suffix added to the model name.\n",
    "tracer_csv:                          Csv file with tracer zones.\n",
    "boundary_tracer_ext:                 Suffix to tracer boundary conditions (Should be short to keep MUID length below 41).\n",
    "sim_ext:                             Suffix added to the simulation ID.\n",
    "runoff_tracer                        Toggle runoff tracer.\n",
    "ww_tracer                            Toggle wastewater tracer.\n",
    "gwi_tracer                           Toggle gwi tracer.\n",
    "include_gwi_in_ww                    Toggle whether gwi included in wastewater tracer.\n",
    "tracer_from_original_zone            Toggle whether the tracer is from the original zone.\n",
    "global_zone_only                     Toggle whether to use global tracer only.\n",
    "single_tracer                        Toggle whether to use single tracer only.\n",
    "single_tracer_ids                    List the single tracer ids (suggest ['All','All'])\n",
    "file_suffix = \"_AD\"                  File name suffix.\n",
    "\n",
    " -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f62e5cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PERMANENT CELL 1\n",
    "\n",
    "import sqlite3\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ctypes\n",
    "import shutil\n",
    "import os\n",
    "MessageBox = ctypes.windll.user32.MessageBoxW\n",
    "from System_Assessment_Generate_Models_Variables import *\n",
    "import traceback\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a54162bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Permanent cell 2\n",
    "#Functions\n",
    "\n",
    "def sql_to_df(sql,model):\n",
    "    con = sqlite3.connect(model)\n",
    "    df = pd.read_sql(sql, con)\n",
    "    con.close()\n",
    "    return df\n",
    "\n",
    "def execute_sql(sqls,model):\n",
    "    con = sqlite3.connect(model)\n",
    "    cur = con.cursor()\n",
    "    if type(sqls) == list:\n",
    "        for sql in sqls:\n",
    "            print(sql)\n",
    "            cur.execute(sql)\n",
    "    else:\n",
    "        sql = sqls\n",
    "        print(sql)\n",
    "        cur.execute(sql)\n",
    "    cur.close()\n",
    "    con.commit()\n",
    "    con.close()\n",
    "  \n",
    "def df_to_sql(df,table_name,model):\n",
    "    conn = sqlite3.connect(model)\n",
    "    df.to_sql(table_name, conn, if_exists='replace', index=False)\n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "    \n",
    "def generate_script(script_path,mu_path):  \n",
    "    script_path_new = os.path.splitext(mu_path)[0] + '.cs'\n",
    "    shutil.copy(script_path, script_path_new)\n",
    "    \n",
    "def generate_mupp(model_original,mu_path):\n",
    "    mupp_path_original = os.path.splitext(model_original)[0] + '.mupp'\n",
    "    mupp_path_new = os.path.splitext(mu_path)[0] + '.mupp'   \n",
    "    with open(mupp_path_original, 'r') as source_file, open(mupp_path_new, 'w') as output_file:\n",
    "        for line in source_file:\n",
    "            if line.startswith(r'   DBFilePath = |.'):\n",
    "                output_file.write('   DBFilePath = |.\\\\' + os.path.splitext(os.path.basename(mu_path))[0] + '.sqlite|\\n')\n",
    "            else:\n",
    "                output_file.write(line)\n",
    "                \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c9f216b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Permanent cell 3\n",
    "#Early error catching and initialization\n",
    "\n",
    "mu_paths_append = []\n",
    "\n",
    "if generate_bsf:\n",
    "    for ini in inis:\n",
    "        if np.mod(ini,11.2) > 0:\n",
    "            message = 'ini ' + str(ini) + ' is not a multiple of 11.2\\n\\nContinue?'\n",
    "            if MessageBox(None, message, 'Warning', 4) == 7:\n",
    "                MessageBox(None, \"Please correct inis\", 'Info', 0)\n",
    "                raise ValueError(message)\n",
    "            else:\n",
    "                pass\n",
    "            \n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "613143a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Permanent cell 4\n",
    "#Generate future models\n",
    "try:\n",
    "    if generate_future:\n",
    "\n",
    "        mu_paths = []\n",
    "\n",
    "        keep_cols = ['Catchment','Zone','Year','Pop_ResLD','Pop_ResHD','Pop_Mixed','Area_Com','Area_Ind','Area_Inst']\n",
    "        pop_df = pd.read_excel(population_sheet,sheet_name=population_tab,usecols=keep_cols,dtype={'Catchment': str})\n",
    "\n",
    "        # Melt the DataFrame to combine the columns\n",
    "        columns_to_combine = ['Pop_ResLD', 'Pop_ResHD', 'Pop_Mixed', 'Area_Com', 'Area_Ind', 'Area_Inst']\n",
    "        pop_df_melt = pd.melt(pop_df, id_vars=['Catchment', 'Zone', 'Year'], value_vars=columns_to_combine, var_name='Type', value_name='Value')\n",
    "        pop_df_melt[['Major_type', 'Minor_type']] = pop_df_melt['Type'].str.split('_', n=1, expand=True)\n",
    "        pop_df_melt = pop_df_melt.drop(columns=['Type'])\n",
    "        pop_df_melt['MUID'] = pop_df_melt.Catchment + '_' + pop_df_melt.Minor_type\n",
    "        pop_df_melt\n",
    "\n",
    "        #Check for missing catchments\n",
    "        catchment_years = []\n",
    "        sql = \"SELECT catchmentid FROM msm_Loadpoint GROUP BY catchmentid\"\n",
    "        muids = list(sql_to_df(sql,model_original).catchmentid)\n",
    "\n",
    "        for muid in muids:\n",
    "            for year_scenario in year_scenario_list:\n",
    "                year = year_scenario[0]\n",
    "                catchment_years.append([muid,year])\n",
    "        catchment_year_df = pd.DataFrame(catchment_years,columns=(['Catchment','Year']))\n",
    "        catchment_year_df \n",
    "\n",
    "        merged = catchment_year_df.merge(pop_df[['Catchment', 'Year']], on=['Catchment', 'Year'], how='left', indicator=True)\n",
    "\n",
    "        not_founds = merged[merged['_merge'] == 'left_only'].drop(columns=['_merge'])\n",
    "\n",
    "        if len(not_founds) > 0:\n",
    "            message = \"WARNING.The following catchment/year combinations are not found\\n\\n\"\n",
    "            for index, row in not_founds.iterrows():\n",
    "                message += row[0] + ', ' + str(row[1]) + '.\\n'\n",
    "            message += '\\nContinue?'\n",
    "\n",
    "            if MessageBox(None, message, 'Warning', 4) == 7:\n",
    "                MessageBox(None, \"Please report the missing catchment(s)\", 'Info', 0)\n",
    "                raise ValueError(message)\n",
    "            else:\n",
    "                pass\n",
    "\n",
    "        for year_scenario in year_scenario_list:\n",
    "            year = year_scenario[0]\n",
    "            scenario = year_scenario[1]\n",
    "            turnons = year_scenario[2]\n",
    "\n",
    "            model_name = model_area + '_' + str(year) + 'pop_V' + str(version) + '.sqlite'\n",
    "\n",
    "            if os.path.basename(model_original) == model_name:\n",
    "\n",
    "                message = \"Tool ends. For year \" + str(year) + \", the new model name '\" + model_name + \"' is the same as the original.\"\n",
    "                MessageBox(None, message, 'Info', 0)\n",
    "                raise ValueError(\"message\")\n",
    "\n",
    "            #Delete sqlite, mupp and cs if they exist and create new\n",
    "            mu_path = output_folder + \"\\\\\" + model_name\n",
    "\n",
    "            mu_paths.append(mu_path)\n",
    "\n",
    "            generate_script(script_path,mu_path)\n",
    "            generate_mupp(model_original,mu_path)\n",
    "\n",
    "            os.remove(mu_path) if os.path.exists(mu_path) else None\n",
    "            shutil.copyfile(model_original, mu_path)\n",
    "\n",
    "            if year != year_original:\n",
    "\n",
    "                sql = \"SELECT MUID FROM msm_Project WHERE enable_hd = 1\"\n",
    "                muids = list(sql_to_df(sql,mu_path).muid)\n",
    "                for muid in muids:\n",
    "                    muid_new = muid.replace(str(year_original) + 'p',str(year) + 'p')\n",
    "                    sql = \"UPDATE msm_Project SET muid = '\" + muid_new + \"' WHERE muid = '\" + muid + \"'\"\n",
    "                    execute_sql(sql, mu_path)\n",
    "\n",
    "                    sql = \"UPDATE msm_ProjectOutput SET simulationid = '\" + muid_new + \"' WHERE simulationid = '\" + muid + \"'\"\n",
    "                    execute_sql(sql, mu_path)\n",
    "\n",
    "                sql = \"UPDATE msm_Project SET IncludeToBatchNo = 0 WHERE MUID LIKE '%h-AES_%'\"\n",
    "                execute_sql(sql, mu_path)\n",
    "\n",
    "                sql = \"UPDATE msm_Project SET scenarioname = '\" + scenario + \"' WHERE MUID NOT LIKE '%h-AES_%' AND enable_hd = 1\"\n",
    "                execute_sql(sql, mu_path)\n",
    "\n",
    "                for turnon in turnons:\n",
    "                    sql = \"UPDATE msm_Project SET IncludeToBatchNo = 1 WHERE MUID LIKE '%h-AES_%' AND MUID LIKE '%\" + turnon + \"%' \"\n",
    "                    sql += \"AND SUBSTR(scenarioname,1,\" + str(len(scenario)) + \") = '\" + scenario  + \"'\"\n",
    "                    execute_sql(sql, mu_path)\n",
    "\n",
    "                pop_df_melt_year = pop_df_melt[pop_df_melt.Year==year]\n",
    "\n",
    "                df_to_sql(pop_df_melt_year,'New_Population',mu_path)\n",
    "\n",
    "                sql = \"UPDATE msm_Loadpoint SET Population = \"\n",
    "                sql += \"(SELECT Value FROM New_Population WHERE MUID = msm_Loadpoint.muid AND Major_Type = 'Pop')\"\n",
    "                execute_sql(sql, mu_path)\n",
    "\n",
    "                sql = \"UPDATE msm_Loadpoint SET ICIArea = \"\n",
    "                sql += \"(SELECT Value FROM New_Population WHERE MUID = msm_Loadpoint.muid AND Major_Type = 'Area')\"\n",
    "                execute_sql(sql, mu_path)\n",
    "\n",
    "                sql = \"UPDATE msm_Loadpoint SET loadflow = PerCapitaLoad * Population / 86400 WHERE LoadCategory = 'Mixed' OR LoadCategory = 'ResLD' OR LoadCategory = 'ResHD'\"\n",
    "                execute_sql(sql, mu_path)\n",
    "                sql = \"UPDATE msm_Loadpoint SET loadflow = PerAreaLoad * ICIArea / 86400 WHERE LoadCategory = 'Commercial' OR LoadCategory = 'Industrial' OR LoadCategory = 'Institutional'\"\n",
    "                execute_sql(sql, mu_path)\n",
    "\n",
    "                sql = \"DROP TABLE New_Population\"\n",
    "                execute_sql(sql, mu_path)\n",
    "\n",
    "except Exception as e: \n",
    "    traceback.print_exc()\n",
    "    MessageBox(None,'An error happened in permanent cell 4', 'Error', 0)\n",
    "    raise ValueError(\"Error\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c77d6d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Permanent cell 5\n",
    "#Generate BSF models\n",
    "try:\n",
    "    if generate_bsf:\n",
    "\n",
    "        if not generate_future:\n",
    "            mu_paths = []\n",
    "            for f in os.listdir(output_folder):\n",
    "                if f[-7:]==\".sqlite\" and not 'BSF' in f and not 'xADWF' in f:\n",
    "                    mu_paths.append(output_folder + '\\\\' + f)\n",
    "\n",
    "\n",
    "        for mu_path_original in mu_paths:\n",
    "\n",
    "            sqls = []\n",
    "\n",
    "            pop_pos = mu_path_original.lower().find('pop')\n",
    "            year = mu_path_original[pop_pos-4:pop_pos]\n",
    "\n",
    "            for ini in inis:\n",
    "\n",
    "                ini_str = str(ini).replace('.','p')\n",
    "\n",
    "                mu_path = mu_path_original[:-7]  + \"_BSF_\" + ini_str + \"k.sqlite\"\n",
    "\n",
    "                mu_paths_append.append(mu_path)\n",
    "\n",
    "                os.remove(mu_path) if os.path.exists(mu_path) else None\n",
    "                shutil.copyfile(mu_path_original, mu_path)\n",
    "\n",
    "                print('Generating ' + mu_path)\n",
    "\n",
    "                generate_script(script_path,mu_path)\n",
    "                generate_mupp(mu_path_original,mu_path)\n",
    "\n",
    "                sql = \"SELECT muid, area, nettypeno FROM msm_Catchment WHERE nettypeno <> 2\"\n",
    "                catchments = sql_to_df(sql,mu_path)\n",
    "\n",
    "                sqls = []\n",
    "                for index, row in catchments.iterrows():\n",
    "                    MUID = str(row[0])\n",
    "                    Area = row[1]\n",
    "                    NetTypeNo = str(row[2])\n",
    "\n",
    "                    flow = Area * ini\n",
    "\n",
    "                    sql = \"UPDATE msm_LoadPoint SET MUID = '\" + MUID + \"_BSF', loadflow = \" + str(flow / 86400 / 10000) + \", Description = 'BSF', LoadCategoryNo = 1, LoadCategory = 'BSF', LoadSubCategory = 'BSF_' & LoadLocation \"\n",
    "                    sql += \"WHERE MUID = '\" + MUID + \"_Load_8'\"\n",
    "\n",
    "                    sqls.append(sql)\n",
    "\n",
    "                execute_sql(sqls, mu_path)\n",
    "\n",
    "                muid_new = model_area + \"_BSF_\" + ini_str + \"k_\" + year + \"pop_\"\n",
    "\n",
    "                sql =  \"DELETE FROM msm_Project WHERE enable_catchment = 1\"\n",
    "                execute_sql(sql, mu_path)\n",
    "\n",
    "                sql = \"SELECT muid FROM msm_Project\"\n",
    "                sims = sql_to_df(sql,mu_path)\n",
    "\n",
    "                for index, row in sims.iterrows():\n",
    "                    muid = row[0]\n",
    "                    if index == 0:\n",
    "                        sql = \"UPDATE msm_Project SET MUID = '\" + muid_new + \"', Description = 'BSF' WHERE MUID = '\" + muid + \"'\"\n",
    "                        execute_sql(sql, mu_path)\n",
    "                        sql = \"UPDATE msm_ProjectOutput SET simulationid = '\" + muid_new + \"' WHERE simulationid = '\" + muid + \"'\"          \n",
    "                        execute_sql(sql, mu_path)\n",
    "                    else:\n",
    "                        sql =  \"DELETE FROM msm_Project WHERE simulationid = '\" + muid + \"'\"\n",
    "                        execute_sql(sql, mu_path)\n",
    "except Exception as e: \n",
    "    traceback.print_exc()\n",
    "    MessageBox(None,'An error happened in permanent cell 5', b'Error', 0)\n",
    "    raise ValueError(\"Error\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a502902",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Permanent cell 6\n",
    "#Generate X ADWF models\n",
    "try:\n",
    "    if generate_xadwf:\n",
    "        deficit_list = []\n",
    "        diurnals = []\n",
    "\n",
    "        if not generate_future:\n",
    "            mu_paths = []\n",
    "            for f in os.listdir(output_folder):\n",
    "                if f[-7:]==\".sqlite\" and not 'BSF' in f and not 'xADWF' in f:\n",
    "                    mu_paths.append(output_folder + '\\\\' + f)\n",
    "\n",
    "        for i, mu_path_original in enumerate(mu_paths):\n",
    "\n",
    "            sqls = []\n",
    "\n",
    "            pop_pos = mu_path_original.lower().find('pop')\n",
    "            year = mu_path_original[pop_pos-4:pop_pos]\n",
    "\n",
    "            sql = \"SELECT Sum(loadflow) AS WaterLoad FROM msm_loadpoint WHERE loadcategory = 'Baseflow'\"\n",
    "            gwi_global = sql_to_df(sql,mu_path_original).iloc[0,0]\n",
    "    #         gwi_global = list(sql_to_df(sql,mu_path_original).WaterLoad)[0]\n",
    "\n",
    "\n",
    "            sql = \"SELECT ms_DPProfileD.ScheduleID AS Day_Type, ms_DPPatternD.Sqn AS [Hour], Sum(msm_Loadpoint.loadflow*ms_DPPatternD.DPValue) + \" + str(gwi_global) + \" AS Discharge \"\n",
    "            sql += \"FROM ((msm_Loadpoint INNER JOIN msm_BBoundary ON msm_Loadpoint.LoadCategoryNo = msm_BBoundary.LoadCategoryNo) INNER JOIN ms_DPProfileD ON msm_BBoundary.DPProfileID = ms_DPProfileD.ProfileID) INNER JOIN ms_DPPatternD ON ms_DPProfileD.PatternID = ms_DPPatternD.PatternID \"\n",
    "            sql += \"WHERE msm_Loadpoint.Active = 1 AND ms_DPProfileD.Active = 1 AND ms_DPPatternD.Active = 1 AND msm_BBoundary.Active = 1 \"\n",
    "            sql += \"GROUP BY ms_DPProfileD.ScheduleID, ms_DPPatternD.Time \"\n",
    "            sql += \"HAVING (LOWER(SUBSTR(ms_DPProfileD.ScheduleID,1,7))='weekday' Or LOWER(SUBSTR(ms_DPProfileD.ScheduleID,1,7))='weekend') AND ms_DPPatternD.Sqn <> 0 \"\n",
    "            sql += \"ORDER BY scheduleid, time\"\n",
    "\n",
    "            diurnal_wws = sql_to_df(sql,mu_path_original)        \n",
    "            diurnal_wws.Hour = diurnal_wws.index\n",
    "            diurnal_wws.loc[diurnal_wws.index > 23, 'HOUR'] = diurnal_wws.index[diurnal_wws.index > 23] - 24\n",
    "\n",
    "            for times_adwf in times_adwf_list:\n",
    "\n",
    "                mu_path = mu_path_original[:-7]  + \"_\" + str(times_adwf).replace('.','p') + \"xADWF.sqlite\"\n",
    "\n",
    "                mu_paths_append.append(mu_path)\n",
    "\n",
    "                os.remove(mu_path) if os.path.exists(mu_path) else None\n",
    "                shutil.copyfile(mu_path_original, mu_path)\n",
    "\n",
    "                print('Generating ' + mu_path)\n",
    "\n",
    "                generate_script(script_path,mu_path)\n",
    "                generate_mupp(mu_path_original,mu_path)\n",
    "\n",
    "                sqls = []\n",
    "\n",
    "                sql = \"SELECT muid FROM msm_Catchment\"\n",
    "                muids = list(sql_to_df(sql,mu_path).muid)\n",
    "                for muid in muids:\n",
    "\n",
    "                    sql = \"SELECT SUM(loadflow) FROM msm_Loadpoint WHERE CatchmentID = '\" + muid + \"' AND msm_Loadpoint.Active = 1\"\n",
    "                    adwf = sql_to_df(sql,mu_path).iloc[0,0]\n",
    "\n",
    "                    sql = \"SELECT SUM(loadflow) FROM msm_Loadpoint WHERE CatchmentID = '\" + muid + \"' AND LoadCategory = 'Baseflow' AND msm_Loadpoint.Active = 1\"\n",
    "                    gwi = sql_to_df(sql,mu_path).iloc[0,0]\n",
    "\n",
    "                    sql = \"SELECT Max(SumOfDPValue) \"\n",
    "                    sql += \"FROM (SELECT \"\n",
    "                    sql += \"ms_DPProfileD.ProfileID, Sum(msm_Loadpoint.loadflow*ms_DPPatternD.DPValue) AS SumOfDPValue \"\n",
    "                    sql += \"FROM ((msm_Loadpoint INNER JOIN msm_BBoundary ON msm_Loadpoint.LoadCategoryNo = msm_BBoundary.LoadCategoryNo) INNER JOIN ms_DPProfileD ON msm_BBoundary.DPProfileID = ms_DPProfileD.ProfileID) INNER JOIN ms_DPPatternD ON ms_DPProfileD.PatternID = ms_DPPatternD.PatternID \"\n",
    "                    sql += \"WHERE msm_Loadpoint.Active = 1 And msm_BBoundary.Active = 1 And ms_DPProfileD.Active = 1 And ms_DPPatternD.Active = 1 \"\n",
    "                    sql += \"GROUP BY ms_DPProfileD.ProfileID,ms_DPPatternD.MUID, msm_Loadpoint.CatchmentID, ms_DPProfileD.ScheduleID \"\n",
    "                    sql += \"HAVING msm_Loadpoint.CatchmentID = '\" + muid + \"' AND (LOWER(SUBSTR(ms_DPProfileD.ScheduleID,1,7))='weekday' Or LOWER(SUBSTR(ms_DPProfileD.ScheduleID,1,7))='weekend'))\"\n",
    "\n",
    "                    pww = sql_to_df(sql,mu_path).iloc[0,0]\n",
    "                    pdwf = gwi + pww\n",
    "                    deficit = times_adwf * adwf - pdwf\n",
    "\n",
    "                    deficit_list.append([os.path.basename(mu_path),muid,deficit])\n",
    "\n",
    "                    sql = \"UPDATE msm_Loadpoint SET muid = '\" + muid + \"_\" + str(times_adwf).replace('.','p') + \"xADWF', \"\n",
    "                    sql += \"loadflow = \" + str(deficit) + \", Description = '\" + str(times_adwf).replace('.','p') + \"xADWF', \"\n",
    "                    sql += \"LoadCategoryNo = 1, LoadCategory = 'X-ADWF', LoadSubCategory = 'X-ADWF_' & LoadLocation \"\n",
    "                    sql += \"WHERE muid = '\" + muid + \"_Load_8'\"\n",
    "                    sqls.append(sql)\n",
    "\n",
    "                execute_sql(sqls, mu_path)\n",
    "\n",
    "                muid_new = model_area + \"_\" + str(times_adwf).replace('.','p') + \"ADWF_\" + year + \"pop_\"\n",
    "                sql =  \"DELETE FROM msm_Project WHERE enable_catchment = 1\"\n",
    "                execute_sql(sql, mu_path)\n",
    "                sql = \"SELECT muid FROM msm_Project\"\n",
    "                sims = sql_to_df(sql,mu_path)\n",
    "                for index, row in sims.iterrows():\n",
    "                    muid = row[0]\n",
    "                    if index == 0:\n",
    "                        sql = \"UPDATE msm_Project SET MUID = '\" + muid_new + \"', Description = 'BSF' WHERE MUID = '\" + muid + \"'\"\n",
    "                        execute_sql(sql, mu_path)\n",
    "                        sql = \"UPDATE msm_ProjectOutput SET simulationid = '\" + muid_new + \"' WHERE simulationid = '\" + muid + \"'\"          \n",
    "                        execute_sql(sql, mu_path)\n",
    "                    else:\n",
    "                        sql =  \"DELETE FROM msm_Project WHERE simulationid = '\" + muid + \"'\"\n",
    "                        execute_sql(sql, mu_path)\n",
    "\n",
    "                sql = \"SELECT Sum(loadflow) FROM msm_Loadpoint WHERE LoadCategory = 'X-ADWF' AND Active = 1\"\n",
    "                deficit = sql_to_df(sql,mu_path).iloc[0,0]\n",
    "\n",
    "                diurnal_wws['Model'] = os.path.basename(mu_path)\n",
    "                diurnal_wws['Deficit'] = deficit\n",
    "                diurnal_wws = diurnal_wws[['Model','Day_Type','Hour','Discharge','Deficit']]\n",
    "\n",
    "                if i == 0:\n",
    "                    diurnals_df = diurnal_wws.copy()\n",
    "                else:\n",
    "                    diurnals_df = pd.concat([diurnals_df,diurnal_wws])           \n",
    "\n",
    "        deficit_df = pd.DataFrame(deficit_list,columns=['Model','Catchment','Deficit'])\n",
    "        deficit_df.to_csv(output_folder + '\\\\Deficits.csv',index=False)\n",
    "\n",
    "        diurnals_df = pd.DataFrame(diurnals,columns=['Model','Day_Type','Hour','Discharge','Deficit'])\n",
    "        diurnals_df.to_csv(output_folder + '\\\\X-ADWF_Diurnals.csv',index=False)\n",
    "\n",
    "    print('Done')\n",
    "except Exception as e: \n",
    "    traceback.print_exc()\n",
    "    MessageBox(None,'An error happened in permanent cell 6', b'Error', 0)\n",
    "    raise ValueError(\"Error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba8f3cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Permanent cell 7\n",
    "#Generate sealed vfd models\n",
    "try:\n",
    "    if generate_sealed_vfd:\n",
    "\n",
    "        if not generate_future:\n",
    "            mu_paths = []\n",
    "            for f in os.listdir(output_folder):\n",
    "                if f[-7:]==\".sqlite\" and not 'VFD' in f:\n",
    "                    mu_paths.append(output_folder + '\\\\' + f)\n",
    "        else:\n",
    "            mu_paths += mu_paths_append\n",
    "\n",
    "        if seal_all and vfd_all:\n",
    "            suffix = \"S_V_\"\n",
    "            file_suffix = \"_Sealed_VFD\"\n",
    "        elif seal_all and not vfd_all:\n",
    "            suffix = \"S_\"\n",
    "            file_suffix = \"_Sealed\"\n",
    "        elif not seal_all and vfd_all:        \n",
    "            suffix = \"V_\"\n",
    "            file_suffix = \"_VFD\" \n",
    "        else:\n",
    "            message = \"Error! generate_sealed_vfd set to True but both vfd_all and seal_all set to False\"\n",
    "            raise ValueError(message)\n",
    "\n",
    "        for mu_path_original in mu_paths:\n",
    "\n",
    "            sqls = []\n",
    "\n",
    "            mu_path = mu_path_original[:-7] + file_suffix + \".sqlite\"\n",
    "            os.remove(mu_path) if os.path.exists(mu_path) else None\n",
    "            shutil.copyfile(mu_path_original, mu_path)\n",
    "\n",
    "            generate_script(script_path,mu_path)\n",
    "            generate_mupp(mu_path_original,mu_path)\n",
    "\n",
    "            print('Generating ' + mu_path)\n",
    "\n",
    "            if seal_all:\n",
    "                sqls.append(\"UPDATE msm_Node SET covertypeno = 2\")\n",
    "                for weir_turn_off in weir_turn_offs:\n",
    "                    sqls.append(\"UPDATE msm_Weir SET crestlevel = crestlevel + 1000 WHERE muid = '\" + weir_turn_off + \"'\")\n",
    "\n",
    "            if vfd_all:\n",
    "\n",
    "                pumps_for_VFD = []\n",
    "                pumps_turn_off = []\n",
    "\n",
    "                sqls.append(\"INSERT INTO ms_Tab (muid,altid,active,description,typeno) SELECT 'Generic_Pump_Min',0,1,'Use for PS passing all inflow',2\")\n",
    "                sqls.append(\"INSERT INTO ms_Tab (muid,altid,active,description,typeno) SELECT 'Generic_Pump_Max',0,1,'Use for PS passing all inflow',2\")\n",
    "\n",
    "                sqls.append(\"INSERT INTO ms_TabD (muid,altid,active,tabid,sqn,value1,value2) SELECT 'Generic_Pump_Max-1',0,1,'Generic_Pump_Max',1, 0, 50\")\n",
    "                sqls.append(\"INSERT INTO ms_TabD (muid,altid,active,tabid,sqn,value1,value2) SELECT 'Generic_Pump_Max-2',0,1,'Generic_Pump_Max',2, 100, 50\")\n",
    "\n",
    "                sqls.append(\"INSERT INTO ms_TabD (muid,altid,active,tabid,sqn,value1,value2) SELECT 'Generic_Pump_Min-1',0,1,'Generic_Pump_Min',1, 0, 0\")\n",
    "                sqls.append(\"INSERT INTO ms_TabD (muid,altid,active,tabid,sqn,value1,value2) SELECT 'Generic_Pump_Min-2',0,1,'Generic_Pump_Min',2, 100, 0\")\n",
    "\n",
    "                sql = \"SELECT MUID FROM msm_Project WHERE enable_hd = 1\"\n",
    "                muids = list(sql_to_df(sql,mu_path).muid)\n",
    "                for muid in muids:\n",
    "                    if len(muid) <= 40 - len(suffix):\n",
    "                        muid_new = muid + suffix\n",
    "                        sqls.append(\"UPDATE msm_Project SET muid = '\" + muid_new + \"' WHERE muid = '\" + muid + \"'\")        \n",
    "                        sqls.append(\"UPDATE msm_ProjectOutput SET simulationid = '\" + muid_new + \"' WHERE simulationid = '\" + muid + \"'\")            \n",
    "\n",
    "                sql = \"SELECT assetname, muid, startlevel from msm_Pump ORDER BY assetname, startlevel\"\n",
    "                pumps = sql_to_df(sql,mu_path)\n",
    "\n",
    "                previous_asset = 'xxxx'\n",
    "                for index, row in pumps.iterrows():\n",
    "                    asset = str(row[0])\n",
    "                    if not asset in excluded_asset_names and asset != 'None':\n",
    "                        muid = str(row[1])\n",
    "                        if previous_asset != asset:\n",
    "                            pumps_for_VFD.append(muid)\n",
    "                        else:\n",
    "                            pumps_turn_off.append (muid)\n",
    "                        previous_asset = asset\n",
    "                    else:\n",
    "                        print ('Skipped ' + str(row[1]))\n",
    "\n",
    "                for pump_for_VFD in pumps_for_VFD:\n",
    "                    sqls.append(\"UPDATE msm_Pump SET qmaxsetid = 'Generic_Pump_Max',  qminsetid = 'Generic_Pump_Min', speedno = 2, captypeno = 2, regno = 1, controltypeno = 2, startlevel = stoplevel + 0.1,  wetwellsetpoint = stoplevel + 0.1  WHERE muid = '\" + pump_for_VFD + \"'\")\n",
    "                    sqls.append(\"UPDATE msm_RTC SET applyno = 0 WHERE pumpid = '\" + pump_for_VFD + \"'\")\n",
    "\n",
    "                for pump_turn_off in pumps_turn_off:\n",
    "                    sqls.append(\"UPDATE msm_Pump SET startlevel = startlevel + 100, stoplevel = stoplevel + 100,  controltypeno = 1 WHERE MUID = '\" + pump_turn_off + \"'\")\n",
    "                    sqls.append(\"UPDATE msm_RTC SET applyno = 0 WHERE pumpid = '\" + pump_turn_off + \"'\")\n",
    "\n",
    "            execute_sql(sqls, mu_path)\n",
    "except Exception as e: \n",
    "    traceback.print_exc()\n",
    "    MessageBox(None,'An error happened in permanent cell 7', b'Error', 0)\n",
    "    raise ValueError(\"Error\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d09559",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PERMANENT CELL 8\n",
    "#Generate AD models.\n",
    "\n",
    "\n",
    "if generate_ad:\n",
    "    \n",
    "    if not generate_future:\n",
    "        mu_paths = []\n",
    "        for f in os.listdir(output_folder):\n",
    "            if f[-7:]==\".sqlite\" and not 'AD' in f:\n",
    "                mu_paths.append(output_folder + '\\\\' + f)\n",
    "\n",
    "    for i, mu_path_original in enumerate(mu_paths):\n",
    "\n",
    "        mu_path = mu_path_original[:-7] + file_suffix + \".sqlite\"\n",
    "        os.remove(mu_path) if os.path.exists(mu_path) else None\n",
    "        shutil.copyfile(mu_path_original, mu_path)\n",
    "\n",
    "        generate_script(script_path,mu_path)\n",
    "        generate_mupp(mu_path_original,mu_path)\n",
    "\n",
    "        sql = \"UPDATE m_ModelSetting SET enable_ad = 1\"\n",
    "        execute_sql(sql, mu_path)\n",
    "        \n",
    "        #Fill tracer zone\n",
    "        sql = \"ALTER TABLE msm_Catchment ADD COLUMN Tracer TEXT\"\n",
    "        execute_sql(sql, mu_path)\n",
    "        \n",
    "        sql = \"ALTER TABLE msm_Catchment ADD COLUMN TracerShort TEXT\"\n",
    "        execute_sql(sql, mu_path)\n",
    "        \n",
    "        \n",
    "        if single_tracer:\n",
    "            tracer = single_tracer_ids[0]\n",
    "            tracer_z = single_tracer_ids[1]\n",
    "            sql = \"UPDATE msm_Catchment SET Tracer = '\" + tracer + \"', TracerShort = '\" + tracer_z + \"'\"\n",
    "            execute_sql(sql, mu_path)\n",
    "        else:\n",
    "            sqls = []\n",
    "            for i, row in tracer_ids.iterrows():\n",
    "                muid = str(row[\"MUID\"])\n",
    "                tracer = str(row[\"Tracer\"])\n",
    "                tracer_z = str(row[\"Tracer_Short\"])\n",
    "                sqls.append(\"UPDATE msm_Catchment SET Tracer = '\" + tracer + \"', TracerShort = '\" + tracer_z + \"'  WHERE MUID = '\" + muid + \"'\")\n",
    "            execute_sql(sqls, mu_path)\n",
    "        \n",
    "        sql = \"CREATE TABLE Tracer_Zones AS \"\n",
    "        sql += \"SELECT Location, Tracer, Location || '_' || TracerShort AS TracerZone \"\n",
    "        sql += \"FROM msm_Catchment WHERE Active = 1 \"\n",
    "        sql += \"GROUP BY Location, Tracer, TracerZone\"\n",
    "        execute_sql(sql, mu_path)\n",
    "\n",
    "        sql = \"SELECT * FROM Tracer_Zones\"\n",
    "        tracer_zones = sql_to_df(sql,mu_path)\n",
    "\n",
    "        sql = \"SELECT CatchID, NodeID, Location, tracer FROM msm_Catchcon INNER JOIN msm_Catchment ON msm_Catchment.MUID = msm_Catchcon.CatchID\"\n",
    "        catchments = sql_to_df(sql,mu_path)\n",
    "\n",
    "        tracers = set()\n",
    "        zones = set()\n",
    "        boundary_names_too_long = set()\n",
    "        old_zones = set()\n",
    "\n",
    "        #\n",
    "\n",
    "        if tracer_from_original_zone == False:\n",
    "            #Create new boundary conditions.\n",
    "\n",
    "            b_type = 'TypeNo'\n",
    "\n",
    "            sqls = []\n",
    "\n",
    "\n",
    "            for index, row in tracer_zones.iterrows():\n",
    "\n",
    "                zone = row['location']\n",
    "                old_zones.add(zone)\n",
    "                \n",
    "\n",
    "                tracer = row['Tracer']\n",
    "                tracer_z = row['TracerZone']\n",
    "\n",
    "                sql = \"CREATE TABLE BTemp AS SELECT * FROM msm_BBoundary WHERE TypeNo = 7 \"\n",
    "                sql += \"AND (SUBSTR(MUID, -\" + str(len(zone)+1) + \") = '_\" + zone + \"' OR MUID = 'Baseflow') AND Active = 1\"\n",
    "                sqls.append(sql)\n",
    "                               \n",
    "                sql = \"UPDATE BTemp SET MUID = SUBSTR(MUID, 1, LENGTH(MUID) -  \" + str(len(zone)+1) + \") || '_\" + tracer_z + \"' WHERE MUID <> 'Baseflow'\"\n",
    "                sqls.append(sql)\n",
    "                \n",
    "\n",
    "                sql = \"UPDATE BTemp SET MUID = 'Baseflow_\" + tracer_z + \"' WHERE MUID = 'Baseflow'\"\n",
    "                sqls.append(sql)\n",
    "\n",
    "                if i == 0:\n",
    "                    sql = \"UPDATE BTemp SET Description = '\" + tracer + \"'\"\n",
    "                    sqls.append(sql)\n",
    "\n",
    "\n",
    "                sql = \"INSERT INTO msm_BBoundary SELECT * FROM BTemp\"\n",
    "                sqls.append(sql)\n",
    "\n",
    "                sql = \"DROP TABLE BTemp\"\n",
    "                sqls.append(sql)\n",
    "\n",
    "            for old_zone in old_zones:\n",
    "                sql = \"DELETE FROM msm_BBoundary WHERE TypeNo = 7 AND SUBSTR(MUID, -\" + str(len(old_zone)) + \") = '\" + old_zone + \"'\"\n",
    "                sqls.append(sql)\n",
    "\n",
    "            sql = \"DELETE FROM msm_BBoundary WHERE MUID = 'Baseflow'\"\n",
    "            sqls.append(sql)\n",
    "\n",
    "            execute_sql(sqls, mu_path)\n",
    "\n",
    "\n",
    "        sqls = []\n",
    "        for c in catchments:\n",
    "            catchment = str(c[0])\n",
    "            node = str(c[1])\n",
    "            zone = str(c[2])\n",
    "\n",
    "            if global_zone_only == True:\n",
    "                tracer = \"Runoff\"\n",
    "            else:\n",
    "                tracer = \"Runoff_\" + str(c[3])\n",
    "\n",
    "            zones.add(zone)\n",
    "\n",
    "            #For later uncomment and update\n",
    "\n",
    "#             if runoff_tracer == True:\n",
    "\n",
    "#                 tracers.add(tracer)\n",
    "\n",
    "#                 boundary_id = 'Runoff_Inflow_' + catchment\n",
    "#                 boundary_tracer_id = boundary_id + boundary_tracer_ext\n",
    "\n",
    "#                 if len(boundary_id) > 40:\n",
    "#                     boundary_names_too_long.add(boundary_id)\n",
    "#                 if len(boundary_tracer_id) > 40:\n",
    "#                     boundary_names_too_long.add(boundary_tracer_id)\n",
    "\n",
    "#                 sql = \"INSERT INTO msm_BBoundary \"\n",
    "#                 sql += \"(MUID, ApplyBoundaryNo, GroupNo, TypeNo, ConnectionTypeNo, SourceLocationNo, IndividualConnectionNo, NodeID, NodeLoadTypeNo, CatchLoadNo, OpenBoundaryNo, Kmix, DistributeNo, LoadCategoryNo, GridTypeNo) \"\n",
    "#                 sql += \"SELECT '\" + boundary_id + \"', 1, 2, 5, 3, 0, 1, '\" + node + \"', 1, 0, 0, 0.5, 0, 1, 1 \"\n",
    "#                 sqls.append(sql)\n",
    "\n",
    "#                 sql = \"INSERT INTO msm_BItem \"\n",
    "#                 sql += \"(MUID, Description, BoundaryID, BoundaryType, TypeNo, TrapComponentID, Fraction, LoadTypeNo, VariationNo, LoadModelNo, ConstantValue, \"\n",
    "#                 sql += \"StartUpNo, StartUpTime, WholeFileNo, ValidityIntervalNo, ValidityBegin, ValidityEnd) \"\n",
    "#                 sql += \"SELECT '\" + boundary_id + \"_T', '\" + boundary_tracer_id + \"', '\" + boundary_id + \"', 5, 2, '\" + tracer + \"', 1, 1, 1, 3, 1, 0, 60, 1, 0, 2, 73051\"\n",
    "#                 sqls.append(sql)\n",
    "\n",
    "#                 sql = \"INSERT INTO msm_BItem \"\n",
    "#                 sql += \"(MUID, Description, BoundaryID, BoundaryType, TypeNo, Fraction, LoadTypeNo, VariationNo, StartUpNo, StartUpTime, BridgeTypeNo, TSConnection, DataTypeName, TimeseriesName, \"\n",
    "#                 sql += \"WholeFileNo, ValidityIntervalNo, ValidityBegin, ValidityEnd) \"\n",
    "#                 sql += \"SELECT '\" + boundary_id + \"', '\" + boundary_id + \"', '\" + boundary_id + \"', 5, 1, 1, 3, 3, 0, 60, 2, '\" + dfs0_file + \"', 'Discharge', '\" + catchment + \"', 1, 0, 2, 73051\"\n",
    "#                 sqls.append(sql)\n",
    "\n",
    "\n",
    "        if ww_tracer == True:\n",
    "\n",
    "            if include_gwi_in_ww == True:\n",
    "                sql = \"SELECT MUID, SUBSTR(MUID, INSTR(MUID, '_') + 1) AS Zone, Description, LoadTypeNo FROM msm_BBoundary WHERE TypeNo = 7 AND Active = 1\"\n",
    "            else:\n",
    "                sql = \"SELECT MUID, SUBSTR(MUID, INSTR(MUID, '_') + 1) AS Zone, Description, LoadTypeNo FROM msm_BBoundary WHERE SUBSTR(MUID,-8) <> 'Baseflow' AND TypeNo = 7 AND Active = 1\"\n",
    "            ww_boundaries = sql_to_df(sql,mu_path)\n",
    "\n",
    "            for index, row in ww_boundaries.iterrows():\n",
    "                boundary_id = row['muid']\n",
    "                boundary_tracer_id = boundary_id + boundary_tracer_ext\n",
    "                tracer = row['description']\n",
    "                load_type = row['loadtypeno']\n",
    "\n",
    "                if len(boundary_id) > 40:\n",
    "                    boundary_names_too_long.add(boundary_id)\n",
    "                if len(boundary_tracer_id) > 40:\n",
    "                    boundary_names_too_long.add(boundary_tracer_id)\n",
    "\n",
    "                if global_zone_only == True:\n",
    "                    zone = \"Wastewater\"\n",
    "                    tracer = \"Wastewater\"\n",
    "                else:\n",
    "                    zone = str(ww_boundary[1])\n",
    "                    tracer = \"Wastewater_\" + tracer\n",
    "\n",
    "                if load_type == 3:\n",
    "                    make_sustom_tracer = False\n",
    "                    for custom_tracer in custom_tracers:\n",
    "                        if boundary_id == custom_tracer[1]:\n",
    "                            make_sustom_tracer = True\n",
    "                            tracer = custom_tracer[0]\n",
    "                    if make_sustom_tracer == False:\n",
    "                        continue\n",
    "\n",
    "                tracers.add(tracer)\n",
    "\n",
    "                sql = \"INSERT INTO msm_WQBoundaryProperties \"\n",
    "                sql += \"(muid,altid,active,enabled,boundaryid,wqboundarytypeno,variationno,constantvalue,cyclicvalue,\"\n",
    "                sql += \"trapcomponentid,startupno,startupvalue,startuptime,fraction) \"\n",
    "                sql += \"SELECT '\" + boundary_tracer_id + \"',0,1,1,'\" + boundary_id + \"',1,1,1,0,'\" + tracer + \"',0,0,60,1\"\n",
    "                sqls.append(sql)\n",
    "#                 sql = \"UPDATE msm_BItem SET Description = MUID WHERE MUID = '\" + boundary_id + \"'\"\n",
    "#                 sqls.append(sql)\n",
    "   \n",
    "        sql = \"SELECT SUBSTR(MUID, INSTR(MUID, '_') + 1) AS Zone FROM msm_BBoundary \"\n",
    "        sql += \"WHERE MUID <> 'Baseflow' AND ConnectionTypeNo = 5 GROUP BY SUBSTR(MUID, INSTR(MUID, '_') + 1)\"\n",
    "        zones = list(sql_to_df(sql,mu_path).Zone.unique())\n",
    "\n",
    "\n",
    "        if gwi_tracer == True and include_gwi_in_ww == False:\n",
    "\n",
    "            sql = \"SELECT MUID, SUBSTR(MUID, INSTR(MUID, '_') + 1) AS Zone, Description FROM msm_BItem \"\n",
    "            sql += \"WHERE SUBSTR(MUID, 1, 8) = 'Baseflow' AND TypeNo = 7\"\n",
    "            gwi_boundaries = sql_to_df(sql,mu_path)\n",
    "\n",
    "            for index, row in gwi_boundaries.iterrows():\n",
    "\n",
    "                boundary_id =row['MUID']\n",
    "                boundary_tracer_id = boundary_id + boundary_tracer_ext\n",
    "                tracer = str(gwi_boundary[2])\n",
    "\n",
    "                if len(boundary_id) > 40:\n",
    "                    boundary_names_too_long.add(boundary_id)\n",
    "                if len(boundary_tracer_id) > 40:\n",
    "                    boundary_names_too_long.add(boundary_tracer_id)\n",
    "\n",
    "                if global_zone_only == True:\n",
    "                    tracer = 'GWI'\n",
    "                    tracers.add(tracer)\n",
    "\n",
    "                else:\n",
    "                    tracer = \"GWI_\" + tracer\n",
    "\n",
    "                    #for zone in zones:\n",
    "                    #tracer = \"GWI_\" + tracer\n",
    "                    tracers.add(tracer)\n",
    "\n",
    "                sql = \"INSERT INTO msm_WQBoundaryProperties \"\n",
    "                sql += \"(muid,altid,active,enabled,boundaryid,wqboundarytypeno,variationno,constantvalue,cyclicvalue,\"\n",
    "                sql += \"trapcomponentid,startupno,startupvalue,startuptime,fraction) \"\n",
    "                sql += \"SELECT '\" + boundary_tracer_id + \"',0,1,1,'\" + boundary_id + \"',1,1,1,0,'\" + tracer + \"',0,0,60,1\"\n",
    "                sqls.append(sql)\n",
    "\n",
    "#                 sql = \"UPDATE msm_BItem SET Description = MUID WHERE MUID = '\" + boundary_id + \"'\"\n",
    "#                 sqls.append(sql)\n",
    "\n",
    "        for tracer in tracers:\n",
    "            sqls.append(\"INSERT INTO msm_ADComponent (muid,altid,active,typeno,decayconst,unitno) SELECT '\" + tracer + \"', 0, 1, 1, 0, 2205\")\n",
    "\n",
    "        if not single_tracer:\n",
    "            for i, row in tracer_ids.iterrows():\n",
    "                muid = str(row[\"MUID\"])\n",
    "                new_zone = str(row[\"Tracer_Short\"])\n",
    "                sqls.append(\"UPDATE msm_Catchment SET Location = Location || '_\" + new_zone + \"' WHERE MUID = '\" + muid + \"'\")\n",
    "                sqls.append(\"UPDATE msm_Loadpoint SET LoadLocation = LoadLocation || '_\" + new_zone + \"', LoadSubCategory = LoadCategory || '_' || LoadLocation || '_\" + new_zone + \"' WHERE CatchmentID = '\" + muid + \"'\")\n",
    "        else:\n",
    "            new_zone = tracer_z\n",
    "            sqls.append(\"UPDATE msm_Catchment SET Location = Location || '_\" + single_tracer_ids[1] + \"'\")\n",
    "            sqls.append(\"UPDATE msm_Loadpoint SET LoadLocation = LoadLocation || '_\" + single_tracer_ids[1] + \"', LoadSubCategory = LoadCategory || '_' || LoadLocation || '_\" + single_tracer_ids[1] + \"'\")\n",
    "\n",
    "        execute_sql(sqls, mu_path)\n",
    "        \n",
    "        sql = \"UPDATE msm_Project SET adinitcondtypeno = 1, decouplingadhdtypeno = 1 WHERE Enable_HD = 1\"\n",
    "        execute_sql(sql, mu_path)\n",
    "\n",
    "        if runoff_tracer == True:\n",
    "            sql = \"UPDATE msm_Project SET Enable_AD = 1, Enable_Catchment = 0, Enable_RR = 0 WHERE Enable_HD = 1\"\n",
    "        else:\n",
    "            sql = \"UPDATE msm_Project SET Enable_AD = 1 WHERE Enable_HD = 1\"\n",
    "        execute_sql(sql, mu_path)\n",
    "        \n",
    "#         sql = \"UPDATE msm_Project SET MUID = MUID || '\" + sim_ext + \"' WHERE Enable_HD = 1 AND LENGTH(MUID) < \" + str(40 - len(sim_ext) + 1)\n",
    "#         execute_sql(sql, mu_path)\n",
    "        \n",
    "        \n",
    "        sql = \"SELECT MUID FROM msm_Project WHERE enable_hd = 1\"\n",
    "        muids = list(sql_to_df(sql,mu_path).muid)\n",
    "        sqls = []\n",
    "        for muid in muids:\n",
    "            if len(muid) <= 40 - len(sim_ext):\n",
    "                muid_new = muid + sim_ext\n",
    "                sqls.append(\"UPDATE msm_Project SET muid = '\" + muid_new + \"' WHERE muid = '\" + muid + \"'\")        \n",
    "                sqls.append(\"UPDATE msm_ProjectOutput SET simulationid = '\" + muid_new + \"' WHERE simulationid = '\" + muid + \"'\") \n",
    "                sql = \"INSERT INTO msm_ProjectOutput (muid, altid, active, simulationid, outputid, contentstypeno, \"\n",
    "                sql += \"formatno, dtsave, dtsaveunitno, defaultsaveperiodno, savestartdate, saveenddate) \"\n",
    "                sql += \"SELECT simulationid || '\" + sim_ext + \"', altid, active, simulationid, 'Default_Network_AD', 12, \"\n",
    "                sql += \"1, 60, 1, 1, savestartdate, saveenddate \"\n",
    "                sql += \"FROM msm_ProjectOutput WHERE simulationid = '\" + muid_new + \"' AND outputid = 'Default_Network_HD'\"\n",
    "                sqls.append(sql)\n",
    "        execute_sql(sqls, mu_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ecf1f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PERMANENT CELL 9\n",
    "MessageBox(None,'All cells ran successfully.', 'Done', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9762dd39",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39_mike",
   "language": "python",
   "name": "py39_mike"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
