{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dea56cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ctypes\n",
    "import shutil\n",
    "import os\n",
    "MessageBox = ctypes.windll.user32.MessageBoxW\n",
    "from System_Assessment_Generate_Models_Variables import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0cbdfac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#FSA System Assessment\n",
    "model_area = 'FSA'\n",
    "model_original = r\"J:\\SEWER_AREA_MODELS\\FSA\\01_MASTER_MODEL\\MODEL\\FSA_Base_2021pop.sqlite\"\n",
    "year_original = 2021\n",
    "version = 103\n",
    "\n",
    "year_scenario_list = []\n",
    "year_scenario_list.append([2034,'2030_Network',['Ex']])\n",
    "# year_scenario_list.append([2040,'2030_Network',['2050M','2050H']])\n",
    "# year_scenario_list.append([2051,'2030_Network',['2050H']])\n",
    "# year_scenario_list.append([2060,'2030_Network',['2050H','2100H']])\n",
    "\n",
    "population_sheet = r\"J:\\SEWER_AREA_MODELS\\FSA\\02_MODEL_COMPONENTS\\04_DATA\\01. POPULATION\\FSA_Master_Population_File_Update14a15a.xlsx\"\n",
    "population_tab = 'MPF Update 14a'\n",
    "all_scenarios = True\n",
    "dual_catchments = False\n",
    "use_all_files_in_folder = False\n",
    "output_folder = r'J:\\SEWER_AREA_MODELS\\FSA\\03_SIMULATION_WORK\\System_Assessment\\Model_Generation'\n",
    "script_path = r'J:\\TOOLS\\Generate_WaterspillDischarge_C#\\WaterspillDischarge.cs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb6971d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sql_to_df(sql,model):\n",
    "  con = sqlite3.connect(model)\n",
    "  df = pd.read_sql(sql, con)\n",
    "  con.close()\n",
    "  return df\n",
    "\n",
    "def execute_sql(sql,model):\n",
    "  con = sqlite3.connect(model)\n",
    "  cur = con.cursor()\n",
    "  cur.execute(sql)\n",
    "  cur.close()\n",
    "  con.commit()\n",
    "  con.close()\n",
    "    \n",
    "def df_to_sql(df,table_name,model):\n",
    "    conn = sqlite3.connect(model)\n",
    "    df.to_sql(table_name, conn, if_exists='replace', index=False)\n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df28411",
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_cols = ['Catchment','Zone','Year','Pop_ResLD','Pop_ResHD','Pop_Mixed','Area_Com','Area_Ind','Area_Inst']\n",
    "pop_df = pd.read_excel(population_sheet,sheet_name=population_tab,usecols=keep_cols,dtype={'Catchment': str})\n",
    "\n",
    "# pop_df = pop_df[pop_df.Catchment!='84394S']\n",
    "# pop_df = pop_df[pop_df.Catchment!='84279']\n",
    "# pop_df = pop_df.drop(pop_df.index[-1])\n",
    "\n",
    "# Melt the DataFrame to combine the columns\n",
    "columns_to_combine = ['Pop_ResLD', 'Pop_ResHD', 'Pop_Mixed', 'Area_Com', 'Area_Ind', 'Area_Inst']\n",
    "pop_df_melt = pd.melt(pop_df, id_vars=['Catchment', 'Zone', 'Year'], value_vars=columns_to_combine, var_name='Type', value_name='Value')\n",
    "pop_df_melt[['Major_type', 'Minor_type']] = pop_df_melt['Type'].str.split('_', n=1, expand=True)\n",
    "pop_df_melt = pop_df_melt.drop(columns=['Type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ad7bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(pop_df_melt['Type'].str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06653c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check for missing catchments\n",
    "catchment_years = []\n",
    "sql = \"SELECT catchmentid FROM msm_Loadpoint GROUP BY catchmentid\"\n",
    "muids = list(sql_to_df(sql,model_original).catchmentid)\n",
    "\n",
    "for muid in muids:\n",
    "    for year_scenario in year_scenario_list:\n",
    "        year = year_scenario[0]\n",
    "        catchment_years.append([muid,year])\n",
    "catchment_year_df = pd.DataFrame(catchment_years,columns=(['Catchment','Year']))\n",
    "catchment_year_df \n",
    "\n",
    "merged = catchment_year_df.merge(pop_df[['Catchment', 'Year']], on=['Catchment', 'Year'], how='left', indicator=True)\n",
    "\n",
    "not_founds = merged[merged['_merge'] == 'left_only'].drop(columns=['_merge'])\n",
    "\n",
    "if len(not_founds) > 0:\n",
    "    message = \"WARNING.The following catchment/year combinations are not found\\n\\n\"\n",
    "    for index, row in not_founds.iterrows():\n",
    "        message += row[0] + ', ' + str(row[1]) + '.\\n'\n",
    "    message += '\\nContinue?'\n",
    "    \n",
    "    if MessageBox(None, message, 'Warning', 4) == 7:\n",
    "        MessageBox(None, \"Please report the missing catchment(s)\", 'Info', 0)\n",
    "        raise ValueError(message)\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "for year_scenario in year_scenario_list:\n",
    "    year = year_scenario[0]\n",
    "    scenario = year_scenario[1]\n",
    "    turnons = year_scenario[2]\n",
    "      \n",
    "    model_name = model_area + '_' + str(year) + 'pop_V' + str(version) + '.sqlite'\n",
    "\n",
    "    if os.path.basename(model_original) == model_name:\n",
    "\n",
    "        message = \"Tool ends. For year \" + str(year) + \", the new model name '\" + model_name + \"' is the same as the original.\"\n",
    "        MessageBox(None, message, 'Info', 0)\n",
    "        raise ValueError(\"message\")\n",
    "\n",
    "    #Delete sqlite if it exists and create a new\n",
    "    mu_path = output_folder + \"\\\\\" + model_name\n",
    "    os.remove(mu_path) if os.path.exists(mu_path) else None\n",
    "    shutil.copyfile(model_original, mu_path)\n",
    "    \n",
    "    script_path_new = os.path.splitext(mu_path)[0] + '.cs'\n",
    "    shutil.copy(script_path, script_path_new)\n",
    "    \n",
    "    mupp_path_original = os.path.splitext(model_original)[0] + '.mupp'\n",
    "    mupp_path_new = os.path.splitext(mu_path)[0] + '.mupp'\n",
    "    \n",
    "    with open(mupp_path_original, 'r') as source_file, open(mupp_path_new, 'w') as output_file:\n",
    "        for line in source_file:\n",
    "            if line.startswith(r'   DBFilePath = |.'):\n",
    "                output_file.write('   DBFilePath = |.\\\\' + os.path.splitext(model_name)[0] + '.sqlite|\\n')\n",
    "            else:\n",
    "                output_file.write(line)\n",
    "    \n",
    "\n",
    "    sql = \"SELECT MUID FROM msm_Project WHERE enable_hd = 1\"\n",
    "    muids = list(sql_to_df(sql,mu_path).muid)\n",
    "    for muid in muids:\n",
    "        muid_new = muid.replace(str(year_original) + 'p',str(year) + 'p')\n",
    "        sql = \"UPDATE msm_Project SET scenarioname = '\" + scenario + \"', muid = '\" + muid_new + \"' WHERE muid = '\" + muid + \"'\"\n",
    "        execute_sql(sql, mu_path)\n",
    "        \n",
    "        sql = \"UPDATE msm_ProjectOutput SET simulationid = '\" + muid_new + \"' WHERE simulationid = '\" + muid + \"'\"\n",
    "        execute_sql(sql, mu_path)\n",
    "        \n",
    "\n",
    "    sql = \"UPDATE msm_Project SET IncludeToBatchNo = 0 WHERE MUID LIKE '%h-AES_%'\"\n",
    "    execute_sql(sql, mu_path)\n",
    "\n",
    "    for turnon in turnons:\n",
    "        sql = \"UPDATE msm_Project SET IncludeToBatchNo = 1 WHERE MUID LIKE '%h-AES_%' AND MUID LIKE '%\" + turnon + \"%'\"\n",
    "        execute_sql(sql, mu_path)\n",
    "        \n",
    "        \n",
    "    pop_df_melt_year = pop_df_melt[pop_df_melt.Year==year]\n",
    "    df_to_sql(pop_df_melt_year,'New_Population',mu_path)\n",
    "    \n",
    "       \n",
    "# del mu_path   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd9b922f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_to_sql(pop_df_melt_year,'New_Population',mu_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c17ccc05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "mu_path = r\"J:\\SEWER_AREA_MODELS\\FSA\\03_SIMULATION_WORK\\System_Assessment\\Model_Generation\\FSA_2033pop_V103 - Copy.sqlite\"\n",
    "\n",
    "# Sample DataFrame\n",
    "data = {'ID': [1, 2, 3],\n",
    "        'Name': ['Alice', 'Bob', 'Charlie']}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Define the SQLite database filename\n",
    "\n",
    "\n",
    "# Establish a connection to the SQLite database\n",
    "conn = sqlite3.connect(mu_path)\n",
    "\n",
    "# Export the DataFrame to an SQLite table\n",
    "table_name = 'MyTables'  # Name of the table in the database\n",
    "# pop_df_melt_year[['Zone','Value']].to_sql(table_name, conn, if_exists='replace', index=False)\n",
    "df.to_sql(table_name, conn, if_exists='replace', index=False)\n",
    "\n",
    "# Commit the changes and close the connection\n",
    "conn.commit()\n",
    "conn.close()\n",
    "\n",
    "print(f\"DataFrame exported to '{table_name}' in '{mu_path}'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccaeabd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "del conn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47457beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample DataFrame\n",
    "data = {'ID': [1, 2, 3],\n",
    "        'Name': ['Alice', 'Bob', 'Charlie']}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Define the SQLite database filename\n",
    "db_filename = r\"J:\\SEWER_AREA_MODELS\\FSA\\03_SIMULATION_WORK\\System_Assessment\\Model_Generation\\FSA_2033pop_V103 - Copy.sqlite\"\n",
    "\n",
    "\n",
    "try:\n",
    "    # Establish a connection to the SQLite database\n",
    "    conn = sqlite3.connect(db_filename)\n",
    "\n",
    "    # Export the DataFrame to an SQLite table\n",
    "    table_name = 'my_tabless'  # Name of the table in the database\n",
    "    df.to_sql(table_name, conn, if_exists='replace', index=False)\n",
    "\n",
    "    # Commit the changes and close the connection\n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "\n",
    "    print(f\"DataFrame exported to '{table_name}' in '{db_filename}'\")\n",
    "except Exception as e:\n",
    "    print(f\"Error: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14baf03d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39_mike",
   "language": "python",
   "name": "py39_mike"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
